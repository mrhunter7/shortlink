# 1. Init

Date: 2023-12-25

## Status

Accepted

## Context

Our Chat Service's voice functionality requires robust speech-to-text capabilities. 
Key considerations include user privacy, service reliability, and processing efficiency. 
Integrating a speech-to-text service raises questions about data privacy, dependency on consistent internet connectivity, 
and potential latency. The use of external services can also introduce data sovereignty and compliance issues. 
The need to store and manipulate audio files (requiring conversion to a specific format like WAV 16bit for standardization) 
adds complexity to the decision. We have an existing infrastructure that includes MinIO, an S3-compatible storage solution, 
which we utilize for storing audio files.

## Decision

We are integrating `whisper.cpp` as our primary local speech-to-text solution to address privacy and latency concerns. 
It operates independently of external services, ensuring functionality in varying network conditions. 
To accommodate scenarios demanding higher accuracy or specific features, we will offer optional integrations with 
Yandex Recognize and Google's Speech-to-Text service.

To handle audio files, we will leverage our existing MinIO storage infrastructure. 
Additionally, we plan to implement an audio conversion module that can convert various audio formats to WAV 16bit, 
ensuring compatibility and standardization across different speech-to-text services.

## Consequences

This hybrid approach with `whisper.cpp` ensures data privacy and reduces latency by processing data locally. 
It also guarantees functionality in offline scenarios. However, it may offer limited accuracy and fewer features compared 
to cloud-based solutions. The optional cloud-based services provide flexibility and high accuracy but introduce potential 
privacy and dependency concerns.

Utilizing MinIO for audio file storage ensures efficient management and accessibility of audio data within our infrastructure. 
The audio conversion module will add complexity to the system but is essential for standardizing audio inputs for consistent
speech-to-text processing.

Adopting multiple speech-to-text solutions and managing an audio conversion system will require careful planning, 
development effort, and robust testing to ensure seamless integration and maintainability. We will need to monitor 
and manage these trade-offs, keeping in mind user feedback and system performance.

## References

1. `whisper.cpp`: An open-source C++ implementation of the Whisper speech-to-text model, available on GitHub. [GitHub - ggerganov/whisper.cpp](https://github.com/ggerganov/whisper.cpp)
2. Original Whisper Project: The original Whisper model by OpenAI, serving as the basis for `whisper.cpp`. [OpenAI - Whisper](https://openai.com/index/whisper/)
3. Yandex Recognize: A cloud-based speech recognition service provided by Yandex. [Yandex Recognize](https://cloud.yandex.com/en-ru/services/speechkit)
4. Google's Speech-to-Text Service: Google's cloud-based speech recognition service offering high accuracy and a wide range of features. [Google Cloud Speech-to-Text](https://cloud.google.com/speech-to-text)
